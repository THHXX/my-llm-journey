import os

# 1. ç¦ç”¨ä»£ç†ï¼Œé˜²æ­¢å›½å†… API è®¿é—®å¤±è´¥
os.environ.pop('http_proxy', None)
os.environ.pop('https_proxy', None)

print("ğŸš€ æ­£åœ¨åˆå§‹åŒ– RAG + Agent ç³»ç»Ÿ...")

from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_community.chat_models import ChatTongyi
from langchain.tools.retriever import create_retriever_tool
from langchain.agents import AgentExecutor, create_react_agent
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory

# ==========================================
# ç¬¬ä¸€æ­¥ï¼šRAG ç³»ç»Ÿæ„å»º (çŸ¥è¯†åº“)
# ==========================================

# 1. åŠ è½½æœ¬åœ°æ³•å¾‹æ–‡æ¡£
doc_path = os.path.join(os.path.dirname(__file__), "law_sample.txt")
if not os.path.exists(doc_path):
    print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {doc_path}")
    exit(1)

loader = TextLoader(doc_path, encoding='utf-8')
docs = loader.load()

# 2. åˆ†å‰²æ–‡æ¡£
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
texts = text_splitter.split_documents(docs)

# 3. åˆ›å»ºå‘é‡æ•°æ®åº“ (ä½¿ç”¨ DashScope Embeddingï¼Œæ— éœ€æœ¬åœ°ä¸‹è½½æ¨¡å‹)
# æ³¨æ„ï¼šDashScopeEmbeddings éœ€è¦ DASHSCOPE_API_KEY
print("ğŸ“¦ æ­£åœ¨æ„å»ºå‘é‡æ•°æ®åº“ (Embedding)...")
embeddings = DashScopeEmbeddings(model="text-embedding-v1")
vectorstore = FAISS.from_documents(texts, embeddings)

# 4. åˆ›å»ºæ£€ç´¢å™¨
retriever = vectorstore.as_retriever()

# ==========================================
# ç¬¬äºŒæ­¥ï¼šAgent ç³»ç»Ÿæ„å»º (å¤§è„‘ + å·¥å…·)
# ==========================================

# 1. å®šä¹‰å·¥å…·ï¼šå°†æ£€ç´¢å™¨å°è£…ä¸º Agent å¯ç”¨çš„å·¥å…·
tool = create_retriever_tool(
    retriever,
    "search_legal_docs",
    "ç”¨äºæœç´¢æ³•å¾‹æ³•è§„å’ŒåˆåŒç›¸å…³çŸ¥è¯†ã€‚å½“ç”¨æˆ·è¯¢é—®æ³•å¾‹é—®é¢˜æ—¶ï¼Œå¿…é¡»ä½¿ç”¨æ­¤å·¥å…·æŸ¥æ‰¾ä¿¡æ¯ã€‚"
)
tools = [tool]

# 2. åˆå§‹åŒ–å¤§æ¨¡å‹ (Qwen-Max)
llm = ChatTongyi(model="qwen-max")

# 3. å®šä¹‰ Prompt æ¨¡æ¿ (ReAct æ¨¡å¼)
template = """Answer the following questions as best you can. You have access to the following tools:

{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

Question: {input}
Thought:{agent_scratchpad}"""

prompt = PromptTemplate.from_template(template)

# 4. åˆ›å»º Agent
agent = create_react_agent(llm, tools, prompt)

# 5. åˆ›å»º Agent æ‰§è¡Œå™¨ (å¸¦è®°å¿†åŠŸèƒ½)
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
agent_executor = AgentExecutor(
    agent=agent, 
    tools=tools, 
    verbose=True, # æ‰“å°æ€è€ƒè¿‡ç¨‹
    handle_parsing_errors=True # å®¹é”™å¤„ç†
)

# ==========================================
# ç¬¬ä¸‰æ­¥ï¼šè¿è¡Œæµ‹è¯•
# ==========================================

def ask(question):
    print(f"\nğŸŸ¢ ç”¨æˆ·æé—®: {question}")
    try:
        result = agent_executor.invoke({"input": question})
        print(f"ğŸ¤– AI å›ç­”: {result['output']}")
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    # æµ‹è¯•é—®é¢˜ 1ï¼šéœ€è¦æ£€ç´¢æ–‡æ¡£
    ask("åˆåŒè¿çº¦éœ€è¦èµ”å¿ä»€ä¹ˆï¼Ÿ")
    
    # æµ‹è¯•é—®é¢˜ 2ï¼šåŸºäºä¸Šä¸‹æ–‡çš„å¤šè½®å¯¹è¯ (è®°å¿†æµ‹è¯•)
    ask("é‚£å¦‚æœè¿çº¦é‡‘å®šå¾—å¤ªé«˜æ€ä¹ˆåŠï¼Ÿ")
