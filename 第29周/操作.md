# 第29周：多模态入门（Qwen-VL）

- 概述
- 安装
- 运行
- 验收
- 备注

## 概述
当前硬件为核显，不满足本地运行 MiniGPT-4 的显存需求。改用 Qwen-VL（通过 DashScope 云端推理）实现中文图文问答与描述，无需本地 GPU。

## 安装
```bash
pip install dashscope pillow
```
确保环境变量 `DASHSCOPE_API_KEY` 已配置为你的 DashScope 密钥。

## 运行
1. 将测试图片命名为 `example.jpg` 放在本目录。
2. 执行示例脚本：
```python
from dashscope import MultiModal

def ask(image_path, prompt):
    resp = MultiModal.chat(
        model='qwen-vl-plus',
        messages=[{
            'role': 'user',
            'content': [
                {'type': 'text', 'text': prompt},
                {'type': 'image', 'image_url': f'file://{image_path}'}
            ]
        }]
    )
    print(resp.output_text)

ask('example.jpg', '图片里有什么？请用中文描述。')
```

## 验收
- 能输出对图片内容的合理中文描述，并正确回答提出的问题。

## 备注
- 需联网；调用失败请检查网络与 `DASHSCOPE_API_KEY`。
- 若后续升级到支持 NVIDIA GPU 的机器，可再按官方 MiniGPT-4 文档切换为本地推理。
- 作为轻量本地替代，可参考 HuggingFace 的 BLIP。