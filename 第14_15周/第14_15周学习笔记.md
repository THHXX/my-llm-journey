<div style="display: flex; align-items: flex-start;">

<!-- 左侧目录 -->
<div style="width: 200px; position: sticky; top: 0; height: 100vh; overflow-y: auto; background-color: #f6f8fa; padding: 20px; border-right: 1px solid #d0d7de; flex-shrink: 0;">

<h3 style="margin-top: 0;">📚 目录导航</h3>

1. [项目概述](#1-项目概述-project)
2. [环境搭建](#2-环境搭建-setup)
3. [代码实战](#3-代码实战-code)
4. [核心参数详解](#4-核心参数详解-params)
    - [生成长度](#41-max_new_tokens)
    - [随机性控制](#42-temperature--do_sample)
5. [踩坑记录](#5-踩坑记录-debug)
    - [回答中断](#51-回答被截断问题)
    - [模型加载慢](#52-模型下载加速)

</div>

<!-- 右侧正文 -->
<div style="flex-grow: 1; padding: 20px; min-width: 0;">

# 第14-15周学习笔记：Qwen-0.5B 本地部署实战

## 1. 项目概述 (Project)
*   **目标**：在本地笔记本（无高端显卡）上运行大语言模型。
*   **模型**：`Qwen/Qwen1.5-0.5B` (通义千问 0.5B 版本)。
*   **特点**：参数量仅 5 亿，占用内存约 2GB，CPU 也能流畅运行。

---

## 2. 环境搭建 (Setup)
使用 `transformers` 库加载模型，使用 `modelscope` 加速下载。

```bash
# 核心依赖
pip install transformers torch accelerate modelscope
```

---

## 3. 代码实战 (Code)

新建 `run_qwen.py`：

```python
from transformers import AutoTokenizer, AutoModelForCausalLM

# 1. 加载模型与分词器
# trust_remote_code=True: 允许运行模型自定义代码
model_id = "qwen/Qwen1.5-0.5B"
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id)

# 2. 准备输入
prompt = "请用一句话介绍你自己。"
inputs = tokenizer(prompt, return_tensors="pt")

# 3. 生成回复 (关键参数配置)
# max_new_tokens=500: 保证回答完整
# temperature=0.7: 增加回答的多样性
pred = model.generate(
    **inputs, 
    max_new_tokens=500, 
    do_sample=True, 
    temperature=0.7
)

# 4. 解码输出
response = tokenizer.decode(pred.cpu()[0], skip_special_tokens=True)
print(f"🤖 回复: {response}")
```

---

## 4. 核心参数详解 (Params)

在 `model.generate()` 函数中，有几个控制生成质量的关键参数：

| 参数名 | 默认值 | 作用 | 通俗解释 |
| :--- | :--- | :--- | :--- |
| **max_new_tokens** | 20 | **最大生成长度** | **“你能说多少个字”**。设得太小（如 100），模型话还没说完就会被强行打断。 |
| **do_sample** | False | **启用采样** | **“是否允许自由发挥”**。False 表示每次都选概率最大的词（死板但稳）；True 表示按概率随机选（灵活但可能胡说）。 |
| **temperature** | 1.0 | **温度（随机度）** | **“脑洞有多大”**。<br>🧊 **< 0.5 (低温)**：冷静、理性、重复。<br>🔥 **> 0.8 (高温)**：热情、发散、甚至疯狂。 |
| **top_k** | 50 | **候选词数量** | 每次只从概率最高的 K 个词里选，防止选到太离谱的词。 |

---

## 5. 踩坑记录 (Debug)

### 5.1 回答被截断问题
*   **现象**：模型回答到一半突然停止，比如“极简主义是一种生”，后面没了。
*   **原因**：`max_new_tokens` 设置过小（默认值或手动设为 100）。
*   **解决**：将 `max_new_tokens` 调大至 `500` 或 `1024`。

### 5.2 模型下载加速
*   **现象**：直接使用 Hugging Face (`transformers`) 下载速度极慢或超时。
*   **解决**：使用 `ModelScope`（魔搭社区）或设置 HF 镜像。
    ```python
    import os
    os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
    ```

</div>
</div>