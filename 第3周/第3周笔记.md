## 第3周：提示工程实战笔记

### 一、本周目标

- **掌握 Prompt 设计的基本套路**：角色设定、明确指令、输出格式约束、少样本示例、自我检查等。
- **围绕同一主题设计 5 类 Prompt**：摘要生成、情感分析、问答、代码生成、多轮对话引导。
- **学会对比「普通版 Prompt」和「优化版 Prompt」的输出差异。**

### 二、核心概念与技巧

- **角色设定（System / 角色提示）**  
  - 给模型一个明确身份（例如「严谨的科技编辑」「客服质检员」），可以让输出风格更稳定、更贴合任务。
- **指令要具体、可量化**  
  - 不说「写一段总结」，而说「用 50–80 字总结」「输出两行：1) 亮点 2) 遗憾」。
- **约束输出格式**  
  - 要求输出 JSON（情感分析）、分点列表（摘要）、结构化小标题，可以让后续程序更好解析。
- **事实边界与拒答规则**  
  - 明确写「只能根据提供的描述回答」「没有答案时说『不知道』」可以减少模型乱编。
- **多轮对话引导**  
  - 预先设计对话步骤（第 1 轮问用途，第 2 轮问预算，第 3 轮确认需求，第 4 轮给建议），让模型按剧本走而不是随意聊天。

### 三、代码文件与结构说明（`prompt_examples.py`）

- **统一演示主题**  
  - 使用了一段关于「智能手表」的中文用户评论，方便 5 类任务横向对比。

- **核心函数**
  - `call_llm(messages, model=None, temperature=0.2)`  
    - 封装一次模型调用，默认从环境变量 `OPENAI_MODEL` 读取模型名称，兼容 DeepSeek 的 OpenAI 接口。
  - `run_summary_examples()`  
    - 对比普通版「请用中文概括下面的评论」与优化版「50–80 字、亮点/遗憾两行」摘要 Prompt。
  - `run_sentiment_examples()`  
    - 对比简单「正向/负向/中立」判断与要求输出 JSON（sentiment/confidence/reason）的结构化情感分析 Prompt。
  - `run_qa_examples()`  
    - 对比自由问答与「只能依据描述回答，不知道就说『不知道』」的严格问答 Prompt。
  - `run_code_examples()`  
    - 对比模糊需求「写个排序代码」与详细规格（函数签名、允许负数和重复值、禁止 sort/sorted、给示例）的代码生成 Prompt。
  - `run_dialogue_examples()`  
    - 对比「随便聊智能手表」和「按 4 个明确步骤进行导购对话」的多轮 Prompt。

- **运行方式（示例）**
  - 先在 PowerShell 中设置 DeepSeek/OpenAI 兼容环境变量：
    - `OPENAI_API_KEY`：API 密钥  
    - `OPENAI_BASE_URL`：如 `https://api.deepseek.com`  
    - `OPENAI_MODEL`：如 `deepseek-chat`
  - 然后运行：
    - `python 第3周\prompt_examples.py  # 依次运行 5 类 Prompt 示例`
  - 可以在 `main()` 里注释掉部分函数，只跑某一类方便截图。

### 四、五类 Prompt 的对比要点

- **摘要生成**
  - 普通版：总结往往比较随意，有时会忽略缺点或写得太长。
  - 优化版：在字数和结构有约束后，输出更紧凑、亮点与遗憾分得更清楚。

- **情感分析**
  - 普通版：只给情感标签，很难看出模型依据是什么。
  - 优化版：输出 JSON，包含置信度和理由，便于程序处理和人工审查。

- **问答**
  - 普通版：有机会「乱补知识」，加入评论中没有的内容。
  - 优化版：明确要求「无则说不知道」，有效降低幻觉。

- **代码生成**
  - 普通版：模型常用内置 `sort/sorted` 草草完成，不一定考虑边界情况。
  - 优化版：有函数签名、数据范围和示例要求后，代码结构和可读性更好。

- **多轮对话引导**
  - 普通版：对话容易发散，不能稳定收集关键信息。
  - 优化版：严格按照步骤提问，更像一个有剧本的导购流程。

### 五、本周踩坑与收获

- **踩坑**
  - 一开始对环境变量与模型选择（OpenAI / DeepSeek）容易混淆，需要理清「代码用统一接口，后端通过环境变量切换」的思路。
- **收获**
  - 体会到：**不改模型，只改 Prompt，就能大幅改变输出质量**。
  - 学会对 Prompt 进行「前后对比实验」，观察准确性、完整性、格式和幻觉情况。

### 六、可继续练习的方向

- 给情感分析和摘要 Prompt 增加「自检」步骤，如：  
  - 让模型检查自己是否遗漏字段、是否超字数。
- 探索更多结构化输出形式，例如表格、多级标题，方便后续自动处理。


