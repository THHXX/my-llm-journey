<div style="display: flex; align-items: flex-start;">

<!-- 左侧目录 -->
<div style="width: 200px; position: sticky; top: 0; height: 100vh; overflow-y: auto; background-color: #f6f8fa; padding: 20px; border-right: 1px solid #d0d7de; flex-shrink: 0;">

<h3 style="margin-top: 0;">📚 目录导航</h3>

1. [任务概述](#1-任务概述)
2. [LoRA 原理简介](#2-lora-原理简介)
3. [环境准备](#3-环境准备)
4. [数据准备](#4-数据准备)
5. [微调实战](#5-微调实战)
6. [推理验证](#6-推理验证)
7. [常见问题](#7-常见问题)

</div>

<!-- 右侧正文 -->
<div style="flex-grow: 1; padding: 20px; min-width: 0;">

# 第18-19周：LoRA 微调实战

## 1. 任务概述

本周我们将深入大模型的核心——**微调 (Fine-tuning)**。
虽然我们无法在个人电脑上重新训练一个 GPT-4，但我们可以通过 **LoRA (Low-Rank Adaptation)** 技术，用极少的资源（普通显卡甚至 CPU）让模型学会特定领域的知识（如法律、医疗）。

**目标**：教会 Qwen-0.5B 模型回答简单的法律问题。

## 2. LoRA 原理简介

| 概念 | 传统微调 | LoRA 微调 | 类比 |
| :--- | :--- | :--- | :--- |
| **参数更新** | 更新模型所有参数 (100%) | 只更新旁路小参数 (<1%) | 
| **显存需求** | 巨大 (需要高端显卡集群) | 很小 (单卡/CPU 可跑) | 
| **类比** | 把整本教科书重写一遍 | 在教科书旁边贴便利贴笔记 |

LoRA 不改变模型原来的权重，而是在旁边挂两个小矩阵（A 和 B），训练时只训练这两个小矩阵。

## 3. 环境准备

需要安装 `peft` 库（Parameter-Efficient Fine-Tuning）。

```bash
# 安装/更新依赖
pip install peft accelerate datasets
```

*注意：如果你有 NVIDIA 显卡，建议安装 CUDA 版本的 PyTorch 以获得几十倍的加速。如果是 CPU，训练会比较慢。*

## 4. 数据准备

我们准备了一个微型的法律问答数据集 `law_data.json`。

**文件内容示例：**
```json
[
    {
        "instruction": "什么是合同法？",
        "input": "",
        "output": "合同法是调整平等主体之间设立、变更、终止民事权利义务关系的法律规范的总称..."
    }
]
```

## 5. 微调实战

运行我们准备好的训练脚本。脚本会自动加载 Qwen-0.5B 模型，并使用 `law_data.json` 进行训练。

**操作步骤：**

1.  打开终端。
2.  进入项目根目录。
3.  运行训练脚本：

```bash
python 第18_19周/train_lora.py
```

**脚本核心逻辑 (`train_lora.py`)：**
*   **加载模型**：`AutoModelForCausalLM`
*   **配置 LoRA**：`LoraConfig` (设置秩 r=8, alpha=32)
*   **应用 LoRA**：`get_peft_model` (此时模型参数量会大幅减少)
*   **训练**：使用 `Trainer` 进行迭代。

训练完成后，LoRA 权重（很小，几 MB）会保存在 `第18_19周/lora_output` 目录下。

## 6. 推理验证

训练完了，模型变聪明了吗？我们来测试一下。

**操作步骤：**

```bash
python 第18_19周/inference_lora.py
```

**预期效果：**
*   **微调前**：问“什么是合同法”，模型可能会胡编乱造或者回答得很泛。
*   **微调后**：模型会倾向于回答我们在 `law_data.json` 里教它的标准答案。

## 7. 常见问题

1.  **显存不足 (OOM)**
    *   **解决**：在 `train_lora.py` 中减小 `per_device_train_batch_size` (比如改为 1)，或者减小 `MAX_LENGTH`。
2.  **训练太慢**
    *   **原因**：没有使用 GPU。
    *   **解决**：耐心等待，或者使用 Colab 等云端 GPU 资源。Qwen-0.5B 在 CPU 上训练少量数据（几条）可能需要几分钟到十几分钟。
3.  **Windows 下 bitsandbytes 报错**
    *   **解决**：本教程特意没有使用 `bitsandbytes` (int8 量化)，直接加载模型，最大程度兼容 Windows 环境。Qwen-0.5B 模型很小，不需要量化也能跑。

</div>
</div>
